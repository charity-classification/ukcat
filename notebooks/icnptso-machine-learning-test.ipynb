{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify charities into ICNP/TSO categories\n",
    "\n",
    "Comparison of machine learning models to get the greatest accuracy.\n",
    "\n",
    "This script runs a number of machine learning models against the manually created sample to determine the best way to produce a classification model that can be run against the full dataset.\n",
    "\n",
    "The models are created using [scikit-learn](https://scikit-learn.org/stable/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "- `pandas` is used to manipulate the data\n",
    "- `sklearn.train_test_split` is used to split the sample data\n",
    "- `nltk` provides functions for preparing the data, plus a list of common stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\drkan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\drkan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the sample data\n",
    "\n",
    "Remove any records which don't have a ICNPTSO category included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    pd.read_csv(\"../data/sample.csv\"),\n",
    "    pd.read_csv(\"../data/top2000.csv\"),\n",
    "]).reset_index()\n",
    "df = df[df[\"ICNPTSO\"].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the training data\n",
    "\n",
    "Create the text corpus by combining the name and activities data. `y` is the ICNPTSO code attached to the charity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6203"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.DataFrame([df[\"name\"], df[\"activities\"]]).T.apply(lambda x: \" \".join(x), axis=1)\n",
    "y = df[\"ICNPTSO\"].values\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare functions used to clean the text data before it's included in the machine learning models. \n",
    "\n",
    "[Lemmatization](https://en.wikipedia.org/wiki/Lemmatisation) is the process where words are turned into the base for of the word - for example \"walking\" becomes \"walk\", \"better\" becomes \"good\".\n",
    "\n",
    "Stopwords (common words like \"and\", \"for\", \"of\") are skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english') + [\n",
    "    \"trust\",\n",
    "    \"fund\",\n",
    "    \"charitable\",\n",
    "    \"charity\",\n",
    "])\n",
    "\n",
    "stemmer = LancasterStemmer()\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "def lemma_words(doc):\n",
    "    return (lemma.lemmatize(w) for w in analyzer(doc))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(lemma.lemmatize(word) for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X` is the list of cleaned values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['lifeline project subject insolvency proceeding object company established object relieve poverty sickness distress among person affected suffer 311 addiction drug kind 312 poor mental emotional physical health 313 obesity 314 sexually transmitted disease including without limitation hiv aid 32 educate public matter relating prevention effective management treatment drug misuse poor mental emotional physical health obesity sexually transmitted disease 33 support assist individual rehabilitation offending view preventing reducing risk crime'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = corpus.apply(clean_text).values\n",
    "np.random.choice(X, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce test and train datasets from `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1241"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test classification models\n",
    "\n",
    "First import the models we're going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "      \"Naive Bayesian\": MultinomialNB(),\n",
    "      \"Linear model - Stochastic gradient descent\": SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None),\n",
    "      \"Logistic Regression\": LogisticRegression(n_jobs=1, C=1e5),\n",
    "      \"Linear Support Vector Classification\": LinearSVC(),\n",
    "      \"Support Vector Classification\": SVC(),\n",
    "#       \"Nu-Support Vector Classification\": NuSVC(),\n",
    "      \"Decision Tree\": DecisionTreeClassifier(max_depth=5),\n",
    "      \"Random Forest\": RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "#       \"MLP Neural Network\": MLPClassifier(alpha=1, max_iter=1000),\n",
    "      \"Ada Boost\": AdaBoostClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each classifier:\n",
    "\n",
    " - create the pipeline\n",
    " - fit the data\n",
    " - predict the values for the test dataset\n",
    " - get the accuracy score for the test dataset\n",
    " - add the results to the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayesian\n",
      "Linear model - Stochastic gradient descent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\drkan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Linear Support Vector Classification\n",
      "Support Vector Classification\n",
      "Decision Tree\n",
      "Random Forest\n",
      "Ada Boost\n"
     ]
    }
   ],
   "source": [
    "accuracy = {}\n",
    "category_results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    nb = Pipeline([\n",
    "                 ('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', clf),\n",
    "              ])\n",
    "    nb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = nb.predict(X_test)\n",
    "\n",
    "    print(name)\n",
    "    accuracy[name] = accuracy_score(y_pred, y_test)\n",
    "    category_results[name] = pd.DataFrame(\n",
    "        classification_report(\n",
    "            y_test,\n",
    "            y_pred,\n",
    "            output_dict=True,\n",
    "            zero_division=0,\n",
    "        )\n",
    "    ).T\n",
    "\n",
    "accuracy = pd.Series(accuracy).rename(\"Accuracy\").to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The results suggest that a Linear Support Vector Classification model produces the best overall accuracy ([`LinearSVC`](https://scikit-learn.org/stable/modules/svm.html#svm-classification)), closely followed by [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "\n",
    "However, because Logistic Regression allows you to see the predicted probabilities for each of the different categories, and given the accuracy achieved by the top 2 is very close, it makes sense to use Logistic Regression model instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Support Vector Classification</th>\n",
       "      <td>0.567284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.557615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear model - Stochastic gradient descent</th>\n",
       "      <td>0.546334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.517325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayesian</th>\n",
       "      <td>0.371475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.223207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada Boost</th>\n",
       "      <td>0.142627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.096696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Accuracy\n",
       "Linear Support Vector Classification        0.567284\n",
       "Logistic Regression                         0.557615\n",
       "Linear model - Stochastic gradient descent  0.546334\n",
       "Support Vector Classification               0.517325\n",
       "Naive Bayesian                              0.371475\n",
       "Decision Tree                               0.223207\n",
       "Ada Boost                                   0.142627\n",
       "Random Forest                               0.096696"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.sort_values(\"Accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results can also be measured on a per-category basis, using the precision, recall and f1 score.\n",
    "\n",
    "- **precision** shows the proportion of the values assigned to a category by the classifier that are correct\n",
    "- **recall** shows the proportion of all the items manually classified into a category that are correctly found by the classifier\n",
    "- the **f1 score** combines these two values using the geometric mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the precision achieved for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A19</th>\n",
       "      <th>A20</th>\n",
       "      <th>A21</th>\n",
       "      <th>A22</th>\n",
       "      <th>A29</th>\n",
       "      <th>A30</th>\n",
       "      <th>B10</th>\n",
       "      <th>...</th>\n",
       "      <th>I90</th>\n",
       "      <th>J10</th>\n",
       "      <th>J20</th>\n",
       "      <th>K10</th>\n",
       "      <th>L40</th>\n",
       "      <th>L50</th>\n",
       "      <th>L60</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayesian</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.835616</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371475</td>\n",
       "      <td>0.154716</td>\n",
       "      <td>0.403668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear model - Stochastic gradient descent</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.546334</td>\n",
       "      <td>0.260501</td>\n",
       "      <td>0.487399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.557615</td>\n",
       "      <td>0.330818</td>\n",
       "      <td>0.549314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Support Vector Classification</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.567284</td>\n",
       "      <td>0.293099</td>\n",
       "      <td>0.534678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.517325</td>\n",
       "      <td>0.263859</td>\n",
       "      <td>0.508912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223207</td>\n",
       "      <td>0.046681</td>\n",
       "      <td>0.172012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096696</td>\n",
       "      <td>0.007835</td>\n",
       "      <td>0.048347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada Boost</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142627</td>\n",
       "      <td>0.010125</td>\n",
       "      <td>0.072096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            A10       A11       A12  A19  A20  \\\n",
       "Naive Bayesian                              0.0  0.835616  1.000000  0.0  0.0   \n",
       "Linear model - Stochastic gradient descent  0.0  0.692308  0.642857  0.0  0.0   \n",
       "Logistic Regression                         0.0  0.852941  0.725490  0.0  1.0   \n",
       "Linear Support Vector Classification        0.0  0.816901  0.633333  0.0  0.0   \n",
       "Support Vector Classification               0.0  0.840580  0.800000  0.0  0.0   \n",
       "Decision Tree                               0.0  0.000000  0.000000  0.0  0.0   \n",
       "Random Forest                               0.0  0.000000  0.000000  0.0  0.0   \n",
       "Ada Boost                                   0.0  0.000000  0.000000  0.0  0.0   \n",
       "\n",
       "                                                 A21       A22  A29  A30  B10  \\\n",
       "Naive Bayesian                              1.000000  0.000000  0.0  0.0  0.0   \n",
       "Linear model - Stochastic gradient descent  0.636364  0.285714  1.0  0.0  0.0   \n",
       "Logistic Regression                         0.777778  0.130435  0.5  0.0  0.0   \n",
       "Linear Support Vector Classification        0.756757  0.142857  1.0  0.0  0.0   \n",
       "Support Vector Classification               0.806452  0.285714  0.0  0.0  0.0   \n",
       "Decision Tree                               0.000000  0.000000  0.0  0.0  0.0   \n",
       "Random Forest                               0.000000  0.000000  0.0  0.0  0.0   \n",
       "Ada Boost                                   0.000000  0.000000  0.0  0.0  0.0   \n",
       "\n",
       "                                            ...       I90  J10       J20  \\\n",
       "Naive Bayesian                              ...  0.000000  0.0  0.000000   \n",
       "Linear model - Stochastic gradient descent  ...  0.333333  0.0  0.500000   \n",
       "Logistic Regression                         ...  0.482759  0.0  0.454545   \n",
       "Linear Support Vector Classification        ...  0.428571  0.0  0.400000   \n",
       "Support Vector Classification               ...  0.400000  0.0  0.666667   \n",
       "Decision Tree                               ...  0.000000  0.0  0.000000   \n",
       "Random Forest                               ...  0.000000  0.0  0.000000   \n",
       "Ada Boost                                   ...  0.000000  0.0  0.000000   \n",
       "\n",
       "                                                 K10  L40       L50       L60  \\\n",
       "Naive Bayesian                              0.500000  0.0  0.000000  0.000000   \n",
       "Linear model - Stochastic gradient descent  0.407407  0.0  0.666667  0.666667   \n",
       "Logistic Regression                         0.416667  0.0  1.000000  1.000000   \n",
       "Linear Support Vector Classification        0.407407  0.0  1.000000  0.666667   \n",
       "Support Vector Classification               0.466667  0.0  1.000000  0.000000   \n",
       "Decision Tree                               0.000000  0.0  0.000000  0.000000   \n",
       "Random Forest                               0.000000  0.0  0.000000  0.000000   \n",
       "Ada Boost                                   0.000000  0.0  0.000000  0.000000   \n",
       "\n",
       "                                            accuracy  macro avg  weighted avg  \n",
       "Naive Bayesian                              0.371475   0.154716      0.403668  \n",
       "Linear model - Stochastic gradient descent  0.546334   0.260501      0.487399  \n",
       "Logistic Regression                         0.557615   0.330818      0.549314  \n",
       "Linear Support Vector Classification        0.567284   0.293099      0.534678  \n",
       "Support Vector Classification               0.517325   0.263859      0.508912  \n",
       "Decision Tree                               0.223207   0.046681      0.172012  \n",
       "Random Forest                               0.096696   0.007835      0.048347  \n",
       "Ada Boost                                   0.142627   0.010125      0.072096  \n",
       "\n",
       "[8 rows x 79 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_summary = pd.concat(category_results).unstack(level=0).T\n",
    "cat_summary.xs(\"precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the recall for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A19</th>\n",
       "      <th>A20</th>\n",
       "      <th>A21</th>\n",
       "      <th>A22</th>\n",
       "      <th>A29</th>\n",
       "      <th>A30</th>\n",
       "      <th>B10</th>\n",
       "      <th>...</th>\n",
       "      <th>I90</th>\n",
       "      <th>J10</th>\n",
       "      <th>J20</th>\n",
       "      <th>K10</th>\n",
       "      <th>L40</th>\n",
       "      <th>L50</th>\n",
       "      <th>L60</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayesian</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.241935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371475</td>\n",
       "      <td>0.084731</td>\n",
       "      <td>0.371475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear model - Stochastic gradient descent</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.546334</td>\n",
       "      <td>0.256875</td>\n",
       "      <td>0.546334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.557615</td>\n",
       "      <td>0.289509</td>\n",
       "      <td>0.557615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Support Vector Classification</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567284</td>\n",
       "      <td>0.278055</td>\n",
       "      <td>0.567284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517325</td>\n",
       "      <td>0.196122</td>\n",
       "      <td>0.517325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223207</td>\n",
       "      <td>0.048832</td>\n",
       "      <td>0.223207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096696</td>\n",
       "      <td>0.013580</td>\n",
       "      <td>0.096696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada Boost</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142627</td>\n",
       "      <td>0.020550</td>\n",
       "      <td>0.142627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            A10       A11       A12  A19  A20  \\\n",
       "Naive Bayesian                              0.0  0.910448  0.241935  0.0  0.0   \n",
       "Linear model - Stochastic gradient descent  0.0  0.940299  0.580645  0.0  0.0   \n",
       "Logistic Regression                         0.0  0.865672  0.596774  0.0  0.5   \n",
       "Linear Support Vector Classification        0.0  0.865672  0.612903  0.0  0.0   \n",
       "Support Vector Classification               0.0  0.865672  0.645161  0.0  0.0   \n",
       "Decision Tree                               0.0  0.000000  0.000000  0.0  0.0   \n",
       "Random Forest                               0.0  0.000000  0.000000  0.0  0.0   \n",
       "Ada Boost                                   0.0  0.000000  0.000000  0.0  0.0   \n",
       "\n",
       "                                                A21  A22    A29  A30  B10  \\\n",
       "Naive Bayesian                              0.03125  0.0  0.000  0.0  0.0   \n",
       "Linear model - Stochastic gradient descent  0.87500  0.2  0.250  0.0  0.0   \n",
       "Logistic Regression                         0.87500  0.3  0.125  0.0  0.0   \n",
       "Linear Support Vector Classification        0.87500  0.2  0.125  0.0  0.0   \n",
       "Support Vector Classification               0.78125  0.2  0.000  0.0  0.0   \n",
       "Decision Tree                               0.00000  0.0  0.000  0.0  0.0   \n",
       "Random Forest                               0.00000  0.0  0.000  0.0  0.0   \n",
       "Ada Boost                                   0.00000  0.0  0.000  0.0  0.0   \n",
       "\n",
       "                                            ...       I90  J10       J20  \\\n",
       "Naive Bayesian                              ...  0.000000  0.0  0.000000   \n",
       "Linear model - Stochastic gradient descent  ...  0.056604  0.0  0.333333   \n",
       "Logistic Regression                         ...  0.264151  0.0  0.555556   \n",
       "Linear Support Vector Classification        ...  0.226415  0.0  0.444444   \n",
       "Support Vector Classification               ...  0.037736  0.0  0.222222   \n",
       "Decision Tree                               ...  0.000000  0.0  0.000000   \n",
       "Random Forest                               ...  0.000000  0.0  0.000000   \n",
       "Ada Boost                                   ...  0.000000  0.0  0.000000   \n",
       "\n",
       "                                               K10  L40  L50  L60  accuracy  \\\n",
       "Naive Bayesian                              0.0625  0.0  0.0  0.0  0.371475   \n",
       "Linear model - Stochastic gradient descent  0.6875  0.0  1.0  1.0  0.546334   \n",
       "Logistic Regression                         0.6250  0.0  1.0  1.0  0.557615   \n",
       "Linear Support Vector Classification        0.6875  0.0  1.0  1.0  0.567284   \n",
       "Support Vector Classification               0.4375  0.0  0.5  0.0  0.517325   \n",
       "Decision Tree                               0.0000  0.0  0.0  0.0  0.223207   \n",
       "Random Forest                               0.0000  0.0  0.0  0.0  0.096696   \n",
       "Ada Boost                                   0.0000  0.0  0.0  0.0  0.142627   \n",
       "\n",
       "                                            macro avg  weighted avg  \n",
       "Naive Bayesian                               0.084731      0.371475  \n",
       "Linear model - Stochastic gradient descent   0.256875      0.546334  \n",
       "Logistic Regression                          0.289509      0.557615  \n",
       "Linear Support Vector Classification         0.278055      0.567284  \n",
       "Support Vector Classification                0.196122      0.517325  \n",
       "Decision Tree                                0.048832      0.223207  \n",
       "Random Forest                                0.013580      0.096696  \n",
       "Ada Boost                                    0.020550      0.142627  \n",
       "\n",
       "[8 rows x 79 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_summary.xs(\"recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score of each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A19</th>\n",
       "      <th>A20</th>\n",
       "      <th>A21</th>\n",
       "      <th>A22</th>\n",
       "      <th>A29</th>\n",
       "      <th>A30</th>\n",
       "      <th>B10</th>\n",
       "      <th>...</th>\n",
       "      <th>I90</th>\n",
       "      <th>J10</th>\n",
       "      <th>J20</th>\n",
       "      <th>K10</th>\n",
       "      <th>L40</th>\n",
       "      <th>L50</th>\n",
       "      <th>L60</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayesian</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371475</td>\n",
       "      <td>0.078124</td>\n",
       "      <td>0.281394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear model - Stochastic gradient descent</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.546334</td>\n",
       "      <td>0.242416</td>\n",
       "      <td>0.491438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.557615</td>\n",
       "      <td>0.293845</td>\n",
       "      <td>0.541313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Support Vector Classification</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.567284</td>\n",
       "      <td>0.271608</td>\n",
       "      <td>0.537796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517325</td>\n",
       "      <td>0.205808</td>\n",
       "      <td>0.468967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223207</td>\n",
       "      <td>0.040701</td>\n",
       "      <td>0.160356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096696</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>0.020971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada Boost</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142627</td>\n",
       "      <td>0.010653</td>\n",
       "      <td>0.075511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            A10       A11       A12  A19  \\\n",
       "Naive Bayesian                              0.0  0.871429  0.389610  0.0   \n",
       "Linear model - Stochastic gradient descent  0.0  0.797468  0.610169  0.0   \n",
       "Logistic Regression                         0.0  0.859259  0.654867  0.0   \n",
       "Linear Support Vector Classification        0.0  0.840580  0.622951  0.0   \n",
       "Support Vector Classification               0.0  0.852941  0.714286  0.0   \n",
       "Decision Tree                               0.0  0.000000  0.000000  0.0   \n",
       "Random Forest                               0.0  0.000000  0.000000  0.0   \n",
       "Ada Boost                                   0.0  0.000000  0.000000  0.0   \n",
       "\n",
       "                                                 A20       A21       A22  \\\n",
       "Naive Bayesian                              0.000000  0.060606  0.000000   \n",
       "Linear model - Stochastic gradient descent  0.000000  0.736842  0.235294   \n",
       "Logistic Regression                         0.666667  0.823529  0.181818   \n",
       "Linear Support Vector Classification        0.000000  0.811594  0.166667   \n",
       "Support Vector Classification               0.000000  0.793651  0.235294   \n",
       "Decision Tree                               0.000000  0.000000  0.000000   \n",
       "Random Forest                               0.000000  0.000000  0.000000   \n",
       "Ada Boost                                   0.000000  0.000000  0.000000   \n",
       "\n",
       "                                                 A29  A30  B10  ...       I90  \\\n",
       "Naive Bayesian                              0.000000  0.0  0.0  ...  0.000000   \n",
       "Linear model - Stochastic gradient descent  0.400000  0.0  0.0  ...  0.096774   \n",
       "Logistic Regression                         0.200000  0.0  0.0  ...  0.341463   \n",
       "Linear Support Vector Classification        0.222222  0.0  0.0  ...  0.296296   \n",
       "Support Vector Classification               0.000000  0.0  0.0  ...  0.068966   \n",
       "Decision Tree                               0.000000  0.0  0.0  ...  0.000000   \n",
       "Random Forest                               0.000000  0.0  0.0  ...  0.000000   \n",
       "Ada Boost                                   0.000000  0.0  0.0  ...  0.000000   \n",
       "\n",
       "                                            J10       J20       K10  L40  \\\n",
       "Naive Bayesian                              0.0  0.000000  0.111111  0.0   \n",
       "Linear model - Stochastic gradient descent  0.0  0.400000  0.511628  0.0   \n",
       "Logistic Regression                         0.0  0.500000  0.500000  0.0   \n",
       "Linear Support Vector Classification        0.0  0.421053  0.511628  0.0   \n",
       "Support Vector Classification               0.0  0.333333  0.451613  0.0   \n",
       "Decision Tree                               0.0  0.000000  0.000000  0.0   \n",
       "Random Forest                               0.0  0.000000  0.000000  0.0   \n",
       "Ada Boost                                   0.0  0.000000  0.000000  0.0   \n",
       "\n",
       "                                                 L50  L60  accuracy  \\\n",
       "Naive Bayesian                              0.000000  0.0  0.371475   \n",
       "Linear model - Stochastic gradient descent  0.800000  0.8  0.546334   \n",
       "Logistic Regression                         1.000000  1.0  0.557615   \n",
       "Linear Support Vector Classification        1.000000  0.8  0.567284   \n",
       "Support Vector Classification               0.666667  0.0  0.517325   \n",
       "Decision Tree                               0.000000  0.0  0.223207   \n",
       "Random Forest                               0.000000  0.0  0.096696   \n",
       "Ada Boost                                   0.000000  0.0  0.142627   \n",
       "\n",
       "                                            macro avg  weighted avg  \n",
       "Naive Bayesian                               0.078124      0.281394  \n",
       "Linear model - Stochastic gradient descent   0.242416      0.491438  \n",
       "Logistic Regression                          0.293845      0.541313  \n",
       "Linear Support Vector Classification         0.271608      0.537796  \n",
       "Support Vector Classification                0.205808      0.468967  \n",
       "Decision Tree                                0.040701      0.160356  \n",
       "Random Forest                                0.003084      0.020971  \n",
       "Ada Boost                                    0.010653      0.075511  \n",
       "\n",
       "[8 rows x 79 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_summary.xs(\"f1-score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the decisions made above we can create and test our final model, based on a logistic regression classifier and using the sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5576148267526189"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = Pipeline([\n",
    "             ('vect', CountVectorizer()),\n",
    "             ('tfidf', TfidfTransformer()),\n",
    "             ('clf', LogisticRegression(n_jobs=5, C=1e5)),\n",
    "          ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predict_proba` gives use the predicted probability of every ICNP/TSO category for each organisation in the sample. This enables us to assess how confident the model is in its estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = nb.predict_proba(X_test)\n",
    "y_pred_proba = pd.DataFrame([\n",
    "    dict(zip(nb.classes_, row))\n",
    "    for row in y_pred_proba\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These predicted probabilities are put into a results table which shows the top 1-3 predicted category for each organisation, along with their probabilities. It also shows the manually assigned category and whether the result matches it exactly or at the sector level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>manual</th>\n",
       "      <th>1st_code</th>\n",
       "      <th>1st_prob</th>\n",
       "      <th>2nd_code</th>\n",
       "      <th>2nd_prob</th>\n",
       "      <th>3rd_code</th>\n",
       "      <th>3rd_prob</th>\n",
       "      <th>correct</th>\n",
       "      <th>sector_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>royal air force association corporate body pro...</td>\n",
       "      <td>D19</td>\n",
       "      <td>D19</td>\n",
       "      <td>0.999233</td>\n",
       "      <td>D14</td>\n",
       "      <td>6.238522e-04</td>\n",
       "      <td>G13</td>\n",
       "      <td>7.886899e-05</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>east sheen baptist church church object promot...</td>\n",
       "      <td>I10</td>\n",
       "      <td>I10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>I90</td>\n",
       "      <td>2.473005e-10</td>\n",
       "      <td>H10</td>\n",
       "      <td>1.457285e-28</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>greatest expectation limited prevention relief...</td>\n",
       "      <td>G11</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.590317</td>\n",
       "      <td>D33</td>\n",
       "      <td>2.448627e-01</td>\n",
       "      <td>B90</td>\n",
       "      <td>1.340572e-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>school around world activity undertaken vary a...</td>\n",
       "      <td>B32</td>\n",
       "      <td>B32</td>\n",
       "      <td>0.903284</td>\n",
       "      <td>B13</td>\n",
       "      <td>9.656150e-02</td>\n",
       "      <td>B90</td>\n",
       "      <td>9.160888e-05</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>collingham district young farmer club yfc prov...</td>\n",
       "      <td>B31</td>\n",
       "      <td>G14</td>\n",
       "      <td>0.714378</td>\n",
       "      <td>F20</td>\n",
       "      <td>2.853841e-01</td>\n",
       "      <td>A21</td>\n",
       "      <td>1.804578e-04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>centre 404 provision social educational activi...</td>\n",
       "      <td>D13</td>\n",
       "      <td>D13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>D14</td>\n",
       "      <td>1.981836e-10</td>\n",
       "      <td>C39</td>\n",
       "      <td>4.615680e-13</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>mission dine club caring elderly community</td>\n",
       "      <td>G15</td>\n",
       "      <td>D12</td>\n",
       "      <td>0.935925</td>\n",
       "      <td>F20</td>\n",
       "      <td>6.258611e-02</td>\n",
       "      <td>D19</td>\n",
       "      <td>5.868527e-04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>police treatment centre advancement health rel...</td>\n",
       "      <td>G11</td>\n",
       "      <td>G11</td>\n",
       "      <td>0.971622</td>\n",
       "      <td>D19</td>\n",
       "      <td>1.815818e-02</td>\n",
       "      <td>C11</td>\n",
       "      <td>9.495898e-03</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>bethel presbyterian church reformed cardiff we...</td>\n",
       "      <td>I10</td>\n",
       "      <td>I10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>I90</td>\n",
       "      <td>4.184751e-10</td>\n",
       "      <td>A90</td>\n",
       "      <td>5.150749e-24</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>human appeal human appeal changed legal struct...</td>\n",
       "      <td>G30</td>\n",
       "      <td>H10</td>\n",
       "      <td>0.686225</td>\n",
       "      <td>G30</td>\n",
       "      <td>3.087997e-01</td>\n",
       "      <td>D33</td>\n",
       "      <td>4.875470e-03</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>limmud limmud unique model crosscommunal grass...</td>\n",
       "      <td>H90</td>\n",
       "      <td>I90</td>\n",
       "      <td>0.978719</td>\n",
       "      <td>H10</td>\n",
       "      <td>1.908238e-02</td>\n",
       "      <td>D11</td>\n",
       "      <td>8.924626e-04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>gateway church company exists church carry typ...</td>\n",
       "      <td>I10</td>\n",
       "      <td>I10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>I90</td>\n",
       "      <td>1.295913e-07</td>\n",
       "      <td>H10</td>\n",
       "      <td>1.268237e-30</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>lichfield university third age educational lei...</td>\n",
       "      <td>B31</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.997521</td>\n",
       "      <td>B21</td>\n",
       "      <td>1.186073e-03</td>\n",
       "      <td>B90</td>\n",
       "      <td>2.457054e-04</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>royal automobile club foundation motoring limi...</td>\n",
       "      <td>G22</td>\n",
       "      <td>K10</td>\n",
       "      <td>0.999340</td>\n",
       "      <td>G11</td>\n",
       "      <td>5.887123e-04</td>\n",
       "      <td>G22</td>\n",
       "      <td>3.413375e-05</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>rnib provision service devolved country cymru ...</td>\n",
       "      <td>D13</td>\n",
       "      <td>D13</td>\n",
       "      <td>0.757317</td>\n",
       "      <td>D19</td>\n",
       "      <td>1.714006e-01</td>\n",
       "      <td>F30</td>\n",
       "      <td>1.692369e-02</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>enfield lgbt network consortium voluntary stat...</td>\n",
       "      <td>F20</td>\n",
       "      <td>D19</td>\n",
       "      <td>0.976012</td>\n",
       "      <td>G11</td>\n",
       "      <td>1.511675e-02</td>\n",
       "      <td>H10</td>\n",
       "      <td>6.497834e-03</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>speranta purpose advancement christian faith s...</td>\n",
       "      <td>I10</td>\n",
       "      <td>I10</td>\n",
       "      <td>0.951526</td>\n",
       "      <td>I90</td>\n",
       "      <td>4.847391e-02</td>\n",
       "      <td>H10</td>\n",
       "      <td>2.871348e-17</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>changing life housing promote social inclusion...</td>\n",
       "      <td>F30</td>\n",
       "      <td>F30</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>G13</td>\n",
       "      <td>1.193390e-09</td>\n",
       "      <td>D32</td>\n",
       "      <td>6.498976e-10</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>rotary club harwich dovercourt hold two event ...</td>\n",
       "      <td>G13</td>\n",
       "      <td>G13</td>\n",
       "      <td>0.960816</td>\n",
       "      <td>H90</td>\n",
       "      <td>3.849372e-02</td>\n",
       "      <td>H10</td>\n",
       "      <td>6.750170e-04</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>st christopher fellowship st christopher provi...</td>\n",
       "      <td>D19</td>\n",
       "      <td>D11</td>\n",
       "      <td>0.894294</td>\n",
       "      <td>F30</td>\n",
       "      <td>9.138446e-02</td>\n",
       "      <td>C32</td>\n",
       "      <td>8.092016e-03</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text manual 1st_code  \\\n",
       "241   royal air force association corporate body pro...    D19      D19   \n",
       "357   east sheen baptist church church object promot...    I10      I10   \n",
       "481   greatest expectation limited prevention relief...    G11      B31   \n",
       "369   school around world activity undertaken vary a...    B32      B32   \n",
       "482   collingham district young farmer club yfc prov...    B31      G14   \n",
       "154   centre 404 provision social educational activi...    D13      D13   \n",
       "577          mission dine club caring elderly community    G15      D12   \n",
       "884   police treatment centre advancement health rel...    G11      G11   \n",
       "816   bethel presbyterian church reformed cardiff we...    I10      I10   \n",
       "1101  human appeal human appeal changed legal struct...    G30      H10   \n",
       "73    limmud limmud unique model crosscommunal grass...    H90      I90   \n",
       "1119  gateway church company exists church carry typ...    I10      I10   \n",
       "605   lichfield university third age educational lei...    B31      B31   \n",
       "150   royal automobile club foundation motoring limi...    G22      K10   \n",
       "780   rnib provision service devolved country cymru ...    D13      D13   \n",
       "655   enfield lgbt network consortium voluntary stat...    F20      D19   \n",
       "242   speranta purpose advancement christian faith s...    I10      I10   \n",
       "115   changing life housing promote social inclusion...    F30      F30   \n",
       "485   rotary club harwich dovercourt hold two event ...    G13      G13   \n",
       "113   st christopher fellowship st christopher provi...    D19      D11   \n",
       "\n",
       "      1st_prob 2nd_code      2nd_prob 3rd_code      3rd_prob  correct  \\\n",
       "241   0.999233      D14  6.238522e-04      G13  7.886899e-05     True   \n",
       "357   1.000000      I90  2.473005e-10      H10  1.457285e-28     True   \n",
       "481   0.590317      D33  2.448627e-01      B90  1.340572e-01    False   \n",
       "369   0.903284      B13  9.656150e-02      B90  9.160888e-05     True   \n",
       "482   0.714378      F20  2.853841e-01      A21  1.804578e-04    False   \n",
       "154   1.000000      D14  1.981836e-10      C39  4.615680e-13     True   \n",
       "577   0.935925      F20  6.258611e-02      D19  5.868527e-04    False   \n",
       "884   0.971622      D19  1.815818e-02      C11  9.495898e-03     True   \n",
       "816   1.000000      I90  4.184751e-10      A90  5.150749e-24     True   \n",
       "1101  0.686225      G30  3.087997e-01      D33  4.875470e-03    False   \n",
       "73    0.978719      H10  1.908238e-02      D11  8.924626e-04    False   \n",
       "1119  1.000000      I90  1.295913e-07      H10  1.268237e-30     True   \n",
       "605   0.997521      B21  1.186073e-03      B90  2.457054e-04     True   \n",
       "150   0.999340      G11  5.887123e-04      G22  3.413375e-05    False   \n",
       "780   0.757317      D19  1.714006e-01      F30  1.692369e-02     True   \n",
       "655   0.976012      G11  1.511675e-02      H10  6.497834e-03    False   \n",
       "242   0.951526      I90  4.847391e-02      H10  2.871348e-17     True   \n",
       "115   1.000000      G13  1.193390e-09      D32  6.498976e-10     True   \n",
       "485   0.960816      H90  3.849372e-02      H10  6.750170e-04     True   \n",
       "113   0.894294      F30  9.138446e-02      C32  8.092016e-03    False   \n",
       "\n",
       "      sector_correct  \n",
       "241             True  \n",
       "357             True  \n",
       "481            False  \n",
       "369             True  \n",
       "482            False  \n",
       "154             True  \n",
       "577            False  \n",
       "884             True  \n",
       "816             True  \n",
       "1101           False  \n",
       "73             False  \n",
       "1119            True  \n",
       "605             True  \n",
       "150            False  \n",
       "780             True  \n",
       "655            False  \n",
       "242             True  \n",
       "115             True  \n",
       "485             True  \n",
       "113             True  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = pd.DataFrame(\n",
    "    data=[\n",
    "        (\n",
    "            list(y_pred_proba.loc[index, :].sort_values(ascending=False).head(3).index) + \\\n",
    "            list(y_pred_proba.loc[index, :].sort_values(ascending=False).head(3).values) + \\\n",
    "            [X_test[index], y_test[index]]\n",
    "        )\n",
    "        for index, row in y_pred_proba.iterrows()\n",
    "    ],\n",
    "    columns=[\"1st_code\", \"2nd_code\", \"3rd_code\", \"1st_prob\", \"2nd_prob\", \"3rd_prob\", \"text\", \"manual\"]\n",
    ")[[\"text\", \"manual\", \"1st_code\", \"1st_prob\", \"2nd_code\", \"2nd_prob\", \"3rd_code\", \"3rd_prob\"]]\n",
    "test_results.loc[:, \"correct\"] = test_results[\"manual\"]==test_results[\"1st_code\"]\n",
    "test_results.loc[:, \"sector_correct\"] = test_results[\"manual\"].str[0]==test_results[\"1st_code\"].str[0]\n",
    "test_results.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing correct and incorrect scores\n",
    "\n",
    "The historgram compares the probability scores for the ones where the match was incorrect (False) with those which were correctly matched (True). There are more organisations with lower probabilities in the incorrect matches, but still a large proportion of the matches are scored correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:title={'center':'False'}>,\n",
       "       <AxesSubplot:title={'center':'True'}>], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_results.hist(column=\"1st_prob\", by=\"correct\", figsize=(10,4), range=(0,1), bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart shows the proportion of matches in each band of probability scores that are correct. It shows that if a cut off of 0.99 was used this would ensure a higher proportion of the results were correct. However, this would leave a number of results as un-categorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='1st_prob'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.crosstab(\n",
    "    pd.cut(test_results[\"1st_prob\"], bins=[0,0.25,0.5,0.75,0.9,0.95,0.99,1]),\n",
    "    test_results[\"correct\"],\n",
    "    normalize='index'\n",
    ").multiply(100).round(1).plot.barh(stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this table shows that using a cut-off of 0.99 would result in 39% of incorrect matches still being used, and 22% of correct matches being disgarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>correct</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st_prob</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0.0, 0.25]</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.25, 0.5]</th>\n",
       "      <td>5.3</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.5, 0.75]</th>\n",
       "      <td>18.4</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.75, 0.9]</th>\n",
       "      <td>13.3</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.9, 0.95]</th>\n",
       "      <td>8.4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.95, 0.99]</th>\n",
       "      <td>15.5</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.99, 1.0]</th>\n",
       "      <td>39.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "correct       False  True \n",
       "1st_prob                  \n",
       "(0.0, 0.25]     0.2    0.0\n",
       "(0.25, 0.5]     5.3    1.7\n",
       "(0.5, 0.75]    18.4    4.2\n",
       "(0.75, 0.9]    13.3    5.8\n",
       "(0.9, 0.95]     8.4    3.0\n",
       "(0.95, 0.99]   15.5    7.2\n",
       "(0.99, 1.0]    39.0   78.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(\n",
    "    pd.cut(test_results[\"1st_prob\"], bins=[0,0.25,0.5,0.75,0.9,0.95,0.99,1]),\n",
    "    test_results[\"correct\"],\n",
    "    normalize='columns'\n",
    ").multiply(100).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two tables show a selection of results from the best (>0.9 probability) and worst (<0.9 probability) results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>manual</th>\n",
       "      <th>1st_code</th>\n",
       "      <th>1st_prob</th>\n",
       "      <th>2nd_code</th>\n",
       "      <th>2nd_prob</th>\n",
       "      <th>3rd_code</th>\n",
       "      <th>3rd_prob</th>\n",
       "      <th>correct</th>\n",
       "      <th>sector_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>royal automobile club foundation motoring limi...</td>\n",
       "      <td>G22</td>\n",
       "      <td>K10</td>\n",
       "      <td>0.999340</td>\n",
       "      <td>G11</td>\n",
       "      <td>5.887123e-04</td>\n",
       "      <td>G22</td>\n",
       "      <td>3.413375e-05</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>cleverhands junior science group objective adv...</td>\n",
       "      <td>B12</td>\n",
       "      <td>K10</td>\n",
       "      <td>0.959601</td>\n",
       "      <td>B90</td>\n",
       "      <td>2.036565e-02</td>\n",
       "      <td>B21</td>\n",
       "      <td>1.374533e-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>coventry faith foundation aim call pure islami...</td>\n",
       "      <td>I90</td>\n",
       "      <td>I10</td>\n",
       "      <td>0.965807</td>\n",
       "      <td>I90</td>\n",
       "      <td>3.409055e-02</td>\n",
       "      <td>H90</td>\n",
       "      <td>4.706277e-05</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>topsham society promote high standard planning...</td>\n",
       "      <td>A12</td>\n",
       "      <td>A12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>G12</td>\n",
       "      <td>5.184541e-08</td>\n",
       "      <td>J20</td>\n",
       "      <td>3.299127e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>gateway church abergavenny christian church pu...</td>\n",
       "      <td>I10</td>\n",
       "      <td>I10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>I90</td>\n",
       "      <td>3.503077e-07</td>\n",
       "      <td>B32</td>\n",
       "      <td>1.108210e-19</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>save child relieve distress promote welfare ch...</td>\n",
       "      <td>G30</td>\n",
       "      <td>D11</td>\n",
       "      <td>0.999780</td>\n",
       "      <td>G11</td>\n",
       "      <td>1.538995e-04</td>\n",
       "      <td>D90</td>\n",
       "      <td>2.244168e-05</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>st teresa school effingham education child wor...</td>\n",
       "      <td>B13</td>\n",
       "      <td>B13</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>I90</td>\n",
       "      <td>2.782932e-05</td>\n",
       "      <td>I10</td>\n",
       "      <td>1.357951e-05</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>magdalen college school oxford limited indepen...</td>\n",
       "      <td>B13</td>\n",
       "      <td>B13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>B32</td>\n",
       "      <td>1.229271e-17</td>\n",
       "      <td>B21</td>\n",
       "      <td>8.799637e-18</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>devon air ambulance devon air ambulance fund o...</td>\n",
       "      <td>C11</td>\n",
       "      <td>C11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>G13</td>\n",
       "      <td>4.711409e-10</td>\n",
       "      <td>D19</td>\n",
       "      <td>3.786406e-10</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>british archaeological association promote stu...</td>\n",
       "      <td>A12</td>\n",
       "      <td>A12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>B21</td>\n",
       "      <td>6.340273e-08</td>\n",
       "      <td>G12</td>\n",
       "      <td>5.620665e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text manual 1st_code  \\\n",
       "150   royal automobile club foundation motoring limi...    G22      K10   \n",
       "467   cleverhands junior science group objective adv...    B12      K10   \n",
       "341   coventry faith foundation aim call pure islami...    I90      I10   \n",
       "155   topsham society promote high standard planning...    A12      A12   \n",
       "146   gateway church abergavenny christian church pu...    I10      I10   \n",
       "680   save child relieve distress promote welfare ch...    G30      D11   \n",
       "324   st teresa school effingham education child wor...    B13      B13   \n",
       "1061  magdalen college school oxford limited indepen...    B13      B13   \n",
       "289   devon air ambulance devon air ambulance fund o...    C11      C11   \n",
       "417   british archaeological association promote stu...    A12      A12   \n",
       "\n",
       "      1st_prob 2nd_code      2nd_prob 3rd_code      3rd_prob  correct  \\\n",
       "150   0.999340      G11  5.887123e-04      G22  3.413375e-05    False   \n",
       "467   0.959601      B90  2.036565e-02      B21  1.374533e-02    False   \n",
       "341   0.965807      I90  3.409055e-02      H90  4.706277e-05    False   \n",
       "155   1.000000      G12  5.184541e-08      J20  3.299127e-08     True   \n",
       "146   1.000000      I90  3.503077e-07      B32  1.108210e-19     True   \n",
       "680   0.999780      G11  1.538995e-04      D90  2.244168e-05    False   \n",
       "324   0.999951      I90  2.782932e-05      I10  1.357951e-05     True   \n",
       "1061  1.000000      B32  1.229271e-17      B21  8.799637e-18     True   \n",
       "289   1.000000      G13  4.711409e-10      D19  3.786406e-10     True   \n",
       "417   1.000000      B21  6.340273e-08      G12  5.620665e-08     True   \n",
       "\n",
       "      sector_correct  \n",
       "150            False  \n",
       "467            False  \n",
       "341             True  \n",
       "155             True  \n",
       "146             True  \n",
       "680            False  \n",
       "324             True  \n",
       "1061            True  \n",
       "289             True  \n",
       "417             True  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results[test_results[\"1st_prob\"]>0.9].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>manual</th>\n",
       "      <th>1st_code</th>\n",
       "      <th>1st_prob</th>\n",
       "      <th>2nd_code</th>\n",
       "      <th>2nd_prob</th>\n",
       "      <th>3rd_code</th>\n",
       "      <th>3rd_prob</th>\n",
       "      <th>correct</th>\n",
       "      <th>sector_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>renfrewshire model railway club objective club...</td>\n",
       "      <td>A12</td>\n",
       "      <td>F12</td>\n",
       "      <td>0.898953</td>\n",
       "      <td>G12</td>\n",
       "      <td>0.037575</td>\n",
       "      <td>A12</td>\n",
       "      <td>0.035406</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>st catherine british school teaching learning ...</td>\n",
       "      <td>B13</td>\n",
       "      <td>H10</td>\n",
       "      <td>0.877321</td>\n",
       "      <td>B32</td>\n",
       "      <td>0.122528</td>\n",
       "      <td>B10</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>leon sterling charity purpose proportion manne...</td>\n",
       "      <td>H10</td>\n",
       "      <td>H10</td>\n",
       "      <td>0.856502</td>\n",
       "      <td>H90</td>\n",
       "      <td>0.141612</td>\n",
       "      <td>L60</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2nd gretna rainbow promoting instruction girl ...</td>\n",
       "      <td>G14</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.821816</td>\n",
       "      <td>G14</td>\n",
       "      <td>0.177390</td>\n",
       "      <td>H10</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>dunard purpose dunard purpose advancement publ...</td>\n",
       "      <td>H10</td>\n",
       "      <td>H10</td>\n",
       "      <td>0.715298</td>\n",
       "      <td>F20</td>\n",
       "      <td>0.284570</td>\n",
       "      <td>A10</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>duke edinburgh award duke edinburgh award prov...</td>\n",
       "      <td>B31</td>\n",
       "      <td>G11</td>\n",
       "      <td>0.631990</td>\n",
       "      <td>H10</td>\n",
       "      <td>0.246759</td>\n",
       "      <td>B32</td>\n",
       "      <td>0.090241</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>barton pooley bridge community make grant init...</td>\n",
       "      <td>F20</td>\n",
       "      <td>F20</td>\n",
       "      <td>0.610438</td>\n",
       "      <td>H10</td>\n",
       "      <td>0.362580</td>\n",
       "      <td>H90</td>\n",
       "      <td>0.026980</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>nysda uk nysda uk uk raise money donation gran...</td>\n",
       "      <td>D33</td>\n",
       "      <td>G11</td>\n",
       "      <td>0.578701</td>\n",
       "      <td>D33</td>\n",
       "      <td>0.329983</td>\n",
       "      <td>D19</td>\n",
       "      <td>0.062391</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>sunderland lion club promoting principle good ...</td>\n",
       "      <td>F20</td>\n",
       "      <td>F20</td>\n",
       "      <td>0.569794</td>\n",
       "      <td>G13</td>\n",
       "      <td>0.429861</td>\n",
       "      <td>H90</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>neuroblastoma uk neuroblastoma uk raise money ...</td>\n",
       "      <td>C12</td>\n",
       "      <td>K10</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>C12</td>\n",
       "      <td>0.484006</td>\n",
       "      <td>C11</td>\n",
       "      <td>0.013948</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text manual 1st_code  \\\n",
       "172   renfrewshire model railway club objective club...    A12      F12   \n",
       "355   st catherine british school teaching learning ...    B13      H10   \n",
       "309   leon sterling charity purpose proportion manne...    H10      H10   \n",
       "1017  2nd gretna rainbow promoting instruction girl ...    G14      B31   \n",
       "706   dunard purpose dunard purpose advancement publ...    H10      H10   \n",
       "206   duke edinburgh award duke edinburgh award prov...    B31      G11   \n",
       "89    barton pooley bridge community make grant init...    F20      F20   \n",
       "61    nysda uk nysda uk uk raise money donation gran...    D33      G11   \n",
       "676   sunderland lion club promoting principle good ...    F20      F20   \n",
       "63    neuroblastoma uk neuroblastoma uk raise money ...    C12      K10   \n",
       "\n",
       "      1st_prob 2nd_code  2nd_prob 3rd_code  3rd_prob  correct  sector_correct  \n",
       "172   0.898953      G12  0.037575      A12  0.035406    False           False  \n",
       "355   0.877321      B32  0.122528      B10  0.000078    False           False  \n",
       "309   0.856502      H90  0.141612      L60  0.000628     True            True  \n",
       "1017  0.821816      G14  0.177390      H10  0.000282    False           False  \n",
       "706   0.715298      F20  0.284570      A10  0.000096     True            True  \n",
       "206   0.631990      H10  0.246759      B32  0.090241    False           False  \n",
       "89    0.610438      H10  0.362580      H90  0.026980     True            True  \n",
       "61    0.578701      D33  0.329983      D19  0.062391    False           False  \n",
       "676   0.569794      G13  0.429861      H90  0.000345     True            True  \n",
       "63    0.502046      C12  0.484006      C11  0.013948    False           False  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results[test_results[\"1st_prob\"]<=0.9].sample(10).sort_values(\"1st_prob\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart compares the frequency of different categories in the actual data compared to the predicted scores, showing how some categories are over-represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzUAAAHcCAYAAADvOISPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7MElEQVR4nO3dedwcVZ3v8e+PJBCTQCAhgEPAJ1eWgEIgBAyyuESGMAgBBAFRQZDgwiiiI3G5Q2au3oujVxBUuJEw4CiLIgEUhwkCMY4ImgRGlgQIECAZlrCFRECW/O4fpzrUU+l++lR3dTonz+f9evXr6a4+deqcU6eW31PVp8zdBQAAAACp2qjbBQAAAACAdhDUAAAAAEgaQQ0AAACApBHUAAAAAEgaQQ0AAACApA3sdgEkacstt/Senp5uFwMAAADAemr+/PnPuPuoet+tF0FNT0+P5s2b1+1iAAAAAFhPmdmjjb7j9jMAAAAASSOoAQAAAJA0ghoAAAAASVsvflMDAAAApO61117T0qVL9corr3S7KEkbPHiwRo8erUGDBkXPQ1ADAAAAVGDp0qXadNNN1dPTIzPrdnGS5O569tlntXTpUo0ZMyZ6Pm4/AwAAACrwyiuvaOTIkQQ0bTAzjRw5svTVLoIaAAAAoCIENO1rpQ0JagAAAAAkjd/UAAAAAB3QM+2GSvNbcs6hleY3Z84cbbzxxnr3u9/dch7Dhg3TqlWrKixVa7hSAwAAAPRDc+bM0W233dbtYlSCoAYAAADYgBxxxBHaa6+99I53vEMzZsyQJN14440aP368xo0bp0mTJmnJkiW66KKLdO6552qPPfbQ7373O5100km6+uqr1+QzbNgwSdKqVas0adIkjR8/Xrvttpuuu+66rtSrL9x+BgAAAGxALrnkEo0YMUIvv/yy9t57b02ZMkWnnnqq5s6dqzFjxui5557TiBEj9KlPfUrDhg3Tl770JUnSzJkz6+Y3ePBgzZo1S5tttpmeeeYZTZw4UYcffvh6NSgCQQ0AAACwATn//PM1a9YsSdLjjz+uGTNm6MADD1zz3JcRI0aUys/d9dWvflVz587VRhttpGXLlumpp57SNttsU3nZW0VQAwAAAGwg5syZo9/85jf6wx/+oCFDhui9732v9thjDy1atKjpvAMHDtTq1aslSatXr9arr74qSfrpT3+q5cuXa/78+Ro0aJB6enpKP0em0/hNDQAAALCBWLFihbbYYgsNGTJEixYt0u23365XXnlFc+fO1SOPPCJJeu655yRJm266qVauXLlm3p6eHs2fP1+SdP311+u1115bk+dWW22lQYMG6dZbb9Wjjz66jmvVHFdqAAAAgA6oegjmGJMnT9ZFF12kXXbZRTvvvLMmTpyoUaNGacaMGTrqqKO0evVqbbXVVrrpppt02GGH6eijj9Z1112nCy64QKeeeqqmTJmicePGafLkyRo6dKgk6YQTTtBhhx2m3XbbTRMmTNDYsWPXeb2aMXfvdhk0YcIEnzdvXreLAQAAALRs4cKF2mWXXbpdjA1CvbY0s/nuPqFeem4/AwAAAJA0ghoAAAAASdswgprpw8MLAAAAQL+zYQQ1AAAAAPotghoAAAAASWsa1JjZJWb2tJndU+e7L5qZm9mW2Wczs/PNbLGZ/dnMxnei0AAAAABQE/OcmkslfV/Sj/MTzWw7SX8r6bHc5EMk7Zi93iXpwuwvAAAA0L9U/Zvv6Suqza+JOXPm6Dvf+Y5+9atf6frrr9d9992nadOm1U37wgsv6PLLL9dnPvOZUsuYPn26hg0bpi996UttlbXplRp3nyvpuTpfnSvpy5LyD7qZIunHHtwuaXMze2tbJQQAAABQmTfeeKP0PIcffnjDgEYKQc0Pf/jDdorVlpZ+U2NmUyQtc/f/Kny1raTHc5+XZtPq5THVzOaZ2bzly5e3UgwAAAAAOUuWLNHYsWN1wgknaJdddtHRRx+tl156ST09PTrrrLM0fvx4/fznP9fs2bO17777avz48TrmmGO0atUqSdKNN96osWPHavz48brmmmvW5HvppZfq9NNPlyQ99dRTOvLIIzVu3DiNGzdOt912m6ZNm6aHHnpIe+yxh/7hH/5BkvTtb39be++9t3bffXedffbZa/L65je/qZ122kn777+/7r///krqHXP7WS9mNkTSVxVuPWuZu8+QNEOSJkyY4E2SAwAAAIhw//33a+bMmdpvv/108sknr7mCMnLkSC1YsEDPPPOMjjrqKP3mN7/R0KFD9a1vfUvf/e539eUvf1mnnnqqbrnlFu2www469thj6+b/uc99Tu95z3s0a9YsvfHGG1q1apXOOecc3XPPPbrrrrskSbNnz9aDDz6oP/7xj3J3HX744Zo7d66GDh2qK6+8UnfddZdef/11jR8/XnvttVfbdS4d1Eh6u6Qxkv7LzCRptKQFZraPpGWStsulHZ1NAwAAALAObLfddtpvv/0kSR/96Ed1/vnnS9KaIOX222/XfffdtybNq6++qn333VeLFi3SmDFjtOOOO66Zd8aMGWvlf8stt+jHPw4/tx8wYICGDx+u559/vlea2bNna/bs2dpzzz0lSatWrdKDDz6olStX6sgjj9SQIUMkhdvaqlA6qHH3uyVtVftsZkskTXD3Z8zsekmnm9mVCgMErHD3JyopKQAAAICmsgsPa30eOnSoJMndddBBB+mKK67ola52laUK7q6vfOUrOu2003pNP++88ypbRl7MkM5XSPqDpJ3NbKmZndJH8l9LeljSYkk/klRu+AMAAAAAbXnsscf0hz/8QZJ0+eWXa//99+/1/cSJE/X73/9eixcvliT95S9/0QMPPKCxY8dqyZIleuihhyRpraCnZtKkSbrwwgslhUEHVqxYoU033VQrV65ck+bggw/WJZdcsua3OsuWLdPTTz+tAw88UNdee61efvllrVy5Ur/85S8rqXPTKzXufnyT73ty713SZ9svFgAAAJC4dTwEc83OO++sH/zgBzr55JO166676tOf/rQuuOCCNd+PGjVKl156qY4//nj99a9/lSR94xvf0E477aQZM2bo0EMP1ZAhQ3TAAQf0ClRqvve972nq1KmaOXOmBgwYoAsvvFD77ruv9ttvP73zne/UIYccom9/+9tauHCh9t13X0nSsGHD9JOf/ETjx4/Xscceq3HjxmmrrbbS3nvvXUmdLcQh3TVhwgSfN29e74n5cb2bdYha2i51HAAAAGDhwoXaZZddulqGJUuW6IMf/KDuueeerpajXfXa0szmu/uEeulbGtIZAAAAANYXBDUAAADABqKnpyf5qzStIKgBAAAAKrI+/LQjda20IUENAAAAUIHBgwfr2WefJbBpg7vr2Wef1eDBg0vN18rDNwEAAAAUjB49WkuXLtXy5cu7XZSkDR48WKNHjy41D0ENAAAAUIFBgwZpzJgx3S5Gv8TtZwAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGlNgxozu8TMnjaze3LTvm1mi8zsz2Y2y8w2z333FTNbbGb3m9nBHSo3AAAAAEiKu1JzqaTJhWk3SXqnu+8u6QFJX5EkM9tV0nGS3pHN80MzG1BZaQEAAACgoGlQ4+5zJT1XmDbb3V/PPt4uaXT2foqkK939r+7+iKTFkvapsLwAAAAA0EsVv6k5WdK/Z++3lfR47rul2bS1mNlUM5tnZvOWL19eQTEAAAAA9EdtBTVm9jVJr0v6adl53X2Gu09w9wmjRo1qpxgAAAAA+rGBrc5oZidJ+qCkSe7u2eRlkrbLJRudTQMAAACAjmjpSo2ZTZb0ZUmHu/tLua+ul3ScmW1iZmMk7Sjpj+0XEwAAAADqa3qlxsyukPReSVua2VJJZyuMdraJpJvMTJJud/dPufu9ZvYzSfcp3Jb2WXd/o1OFBwAAAICmQY27H19n8sw+0n9T0jfbKRQAAAAAxKpi9DMAAAAA6BqCGgAAAABJI6gBAAAAkLSWh3TulJ5pN0iSlgzuckEAAAAAJIErNQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSNrDbBWhVz7Qb1rxfMriLBQEAAADQVVypAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJC0pkGNmV1iZk+b2T25aSPM7CYzezD7u0U23czsfDNbbGZ/NrPxnSw8AAAAAMRcqblU0uTCtGmSbnb3HSXdnH2WpEMk7Zi9pkq6sJpiAgAAAEB9TYMad58r6bnC5CmSLsveXybpiNz0H3twu6TNzeytFZUVAAAAANbS6m9qtnb3J7L3T0raOnu/raTHc+mWZtMAAAAAoCPaHijA3V2Sl53PzKaa2Twzm7d8+fJ2iwEAAACgn2o1qHmqdltZ9vfpbPoySdvl0o3Opq3F3We4+wR3nzBq1KgWiwEAAACgv2s1qLle0onZ+xMlXZeb/vFsFLSJklbkblMDAAAAgMoNbJbAzK6Q9F5JW5rZUklnSzpH0s/M7BRJj0r6cJb815L+TtJiSS9J+kQHygwAAAAAazQNatz9+AZfTaqT1iV9tt1CAQAAAECstgcKAAAAAIBuIqgBAAAAkDSCGgAAAABJ619BzfTh4QUAAABgg9G/ghoAAAAAGxyCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJayuoMbMvmNm9ZnaPmV1hZoPNbIyZ3WFmi83sKjPbuKrCAgAAAEBRy0GNmW0r6XOSJrj7OyUNkHScpG9JOtfdd5D0vKRTqigoAAAAANTT7u1nAyW9xcwGShoi6QlJ75d0dfb9ZZKOaHMZAAAAANBQy0GNuy+T9B1JjykEMyskzZf0gru/niVbKmnbevOb2VQzm2dm85YvX95qMQAAAAD0c+3cfraFpCmSxkj6G0lDJU2Ond/dZ7j7BHefMGrUqFaLAQAAAKCfa+f2sw9IesTdl7v7a5KukbSfpM2z29EkabSkZW2WEQAAAAAaaieoeUzSRDMbYmYmaZKk+yTdKunoLM2Jkq5rr4gAAAAA0Fg7v6m5Q2FAgAWS7s7ymiHpLElnmtliSSMlzaygnAAAAABQ18DmSRpz97MlnV2Y/LCkfdrJFwAAAABitTukMwAAAAB0FUENAAAAgKQR1AAAAABIGkENAAAAgKQR1AAAAABIGkENAAAAgKQR1AAAAABIGkENAAAAgKQR1AAAAABIGkENAAAAgKQR1AAAAABIGkENAAAAgKQR1AAAAABIGkENAAAAgKQR1AAAAABIGkENAAAAgKQR1AAAAABIGkENAAAAgKQR1AAAAABIGkENAAAAgKQN7HYBOq1n2g1r3i8Z3MWCAAAAAOgIrtQAAAAASBpBDQAAAICkEdQAAAAASBpBDQAAAICkEdQAAAAASBpBDQAAAICkEdQAAAAASBpBDQAAAICkbfAP32zJ9OG59yu6Vw4AAAAATXGlBgAAAEDSCGoAAAAAJI3bz3J6pt0gSVoyuMsFAQAAABCNKzUAAAAAkkZQAwAAACBpBDUt6Jl2w5pb1QAAAAB0F0ENAAAAgKQR1AAAAABIGkENAAAAgKQR1AAAAABIGkENAAAAgKQR1AAAAABIGkENAAAAgKQR1AAAAABI2sBuFyBp04fn3q9Yf/MEAAAANmBcqQEAAACQNK7UdFDPtBvWvF9yzqFdLAkAAACw4eJKDQAAAICkEdQAAAAASFpbQY2ZbW5mV5vZIjNbaGb7mtkIM7vJzB7M/m5RVWEBAAAAoKjdKzXfk3Sju4+VNE7SQknTJN3s7jtKujn7DAAAAAAd0XJQY2bDJR0oaaYkufur7v6CpCmSLsuSXSbpiPaKCAAAAACNtXOlZoyk5ZL+1czuNLOLzWyopK3d/YkszZOStq43s5lNNbN5ZjZv+fLlbRQDAAAAQH/WTlAzUNJ4SRe6+56S/qLCrWbu7pK83szuPsPdJ7j7hFGjRrVRDAAAAAD9WTtBzVJJS939juzz1QpBzlNm9lZJyv4+3V4RAQAAAKCxloMad39S0uNmtnM2aZKk+yRdL+nEbNqJkq5rq4QAAAAA0IeBbc7/95J+amYbS3pY0icUAqWfmdkpkh6V9OE2lwEAAAAADbUV1Lj7XZIm1PlqUjv5AgAAAECsdp9TAwAAAABdRVADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSRlADAAAAIGkENQAAAACSNrDbBYDUM+2GNe+XDI5Lu+ScQztZJAAAACAZXKkBAAAAkDSCGgAAAABJI6gBAAAAkDSCGgAAAABJI6gBAAAAkDSCmnVl+vDwAgAAAFApghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0ghoAAAAASSOoAQAAAJA0gpr+YPrw8AIAAAA2QAQ1AAAAAJJGUAMAAAAgaQO7XQB0Rs+0G9a8XzK4iwUBAAAAOowrNQAAAACS1nZQY2YDzOxOM/tV9nmMmd1hZovN7Coz27j9YgIAAABAfVVcqfm8pIW5z9+SdK677yDpeUmnVLAMpKg26hojrwEAAKCD2gpqzGy0pEMlXZx9Nknvl3R1luQySUe0swwAAAAA6Eu7V2rOk/RlSauzzyMlveDur2efl0rats1lAAAAAEBDLY9+ZmYflPS0u883s/e2MP9USVMlafvtt2+1GGhTr1HSzjm0iyUBAAAAWtPOlZr9JB1uZkskXalw29n3JG1uZrVgabSkZfVmdvcZ7j7B3SeMGjWqjWIAAAAA6M9aDmrc/SvuPtrdeyQdJ+kWdz9B0q2Sjs6SnSjpurZLCQAAAAANdOI5NWdJOtPMFiv8xmZmB5YBVIcR2gAAAJLW8m9q8tx9jqQ52fuHJe1TRb4AAAAA0EwnrtQAAAAAwDpDUAMAAAAgaQQ1AAAAAJJWyW9q0M/kf1Q/fUX3ygEAAACIKzUAAAAAEkdQAwAAACBp3H6GaD3TbpAkLRncgcxrt7RxOxsAAABK4koNAAAAgKQR1AAAAABIGrefoXIdvU0NAAAAKOBKDQAAAICkEdQAAAAASBpBDQAAAICkEdQAAAAASBpBDQAAAICkMfoZ0C21B45KPHQUAACgDVypAQAAAJA0ghoAAAAASeP2M3RN7SGdEg/qBAAAQOu4UgMAAAAgaQQ1AAAAAJJGUAMAAAAgaQQ1AAAAAJJGUAMAAAAgaQQ1AAAAAJJGUAMAAAAgaQQ1AAAAAJLGwzdTNX147v2K7pVjHej1kM5zDu1iSQAAALA+4koNAAAAgKQR1AAAAABIGref4U21W9o28NvZOq4f3RoIAACwPuBKDQAAAICkEdQAAAAASBq3n2GDUhsprdkoab1GVBvc0SIBAACgw7hSAwAAACBpXKkBsG4xkAIAAKgYV2oAAAAAJI2gBgAAAEDSCGoAAAAAJI2gBgAAAEDSCGoAAAAAJI3Rz4A+9HqeTeSzb5J47g0jkAEAgA0IV2oAAAAAJI2gBgAAAEDSuP0MAIq4PQ8AgKRwpQYAAABA0ghqAAAAACSN28+AdaylUdJqt0NxKxQAAMBauFIDAAAAIGkENQAAAACS1nJQY2bbmdmtZnafmd1rZp/Ppo8ws5vM7MHs7xbVFRcAAAAAemvnSs3rkr7o7rtKmijps2a2q6Rpkm529x0l3Zx9BgAAAICOaDmocfcn3H1B9n6lpIWStpU0RdJlWbLLJB3RZhkBAAAAoKFKRj8zsx5Je0q6Q9LW7v5E9tWTkrZuMM9USVMlafvtt6+iGMCbNoCHJ9ZGSZNKjpQGAADQz7Q9UICZDZP0C0lnuPuL+e/c3SV5vfncfYa7T3D3CaNGjWq3GAAAAAD6qbaCGjMbpBDQ/NTdr8kmP2Vmb82+f6ukp9srIgAAAAA01s7oZyZppqSF7v7d3FfXSzoxe3+ipOtaLx4AAAAA9K2d39TsJ+ljku42s7uyaV+VdI6kn5nZKZIelfThtkoIAAAAAH1oOahx9/+UZA2+ntRqvgAAAABQRiWjnwHrTDdHNastez0bTa3XKGnnHNrFkgAAAHRH26OfAQAAAEA3EdQAAAAASBpBDQAAAICkEdQAAAAASBpBDQAAAICkMfoZ0I/URkpbMrgDmVc9Olw3R7oDAABJ4UoNAAAAgKQR1AAAAABIGkENgLX0TLuh10M9AQAA1mcENQAAAACSxkABAFqWv5rT1+ADsekAAABawZUaAAAAAEkjqAEAAACQNIIaAAAAAEkjqAEAAACQNIIaAAAAAElj9DMA65XaSGmlRkmbPjz7u6L6AgEAgPUeV2oAAAAAJI2gBgAAAEDSuP0M2JBUfRtWLb8q86xIcg/05BY5AAA6his1AAAAAJJGUAMAAAAgadx+BmCD1vs2tY+ENw1uAWtp5DUAANB1XKkBAAAAkDSCGgAAAABJ4/YzAChpzW1q5xwalU7iljYAADqJKzUAAAAAkkZQAwAAACBp3H4GAK2q6OGkvW5Ti7ylrdStb32kLbNsAADWV1ypAQAAAJA0ghoAAAAASSOoAQBE6Zl2Q6/b1dpNBwBAVQhqAAAAACSNoAYAAABA0hj9DADQGU1Gh2PkNVSm1tfaGIUQQNq4UgMAAAAgaQQ1AAAAAJLG7WcAgPVaR29Tq+gBqgCA7uJKDQAAAICkEdQAAAAASBq3nwEAuq+i0atqt6o1u01tTbrBcfk1y7NXusEfefOLPkZ9iy1jqWXH1rvidDFpAaCTuFIDAAAAIGkENQAAAACSxu1nALA+YTQu1JP4wyU7eYuc1PdthNwiB/QPXKkBAAAAkDSu1ABAispc0Yn9L3/iVwOg8us6Jm0/8uYAEh0Y7KGWZx/5dWzZVQ80EVvGyHSlythHO/ZadkVXBJEOrtQAAAAASBpBDQAAAICkdez2MzObLOl7kgZIutjdz+nUsgAA/QS3Ta1bnWjvDWkdplIXbi1t2frwvKhuLrsjZazoFsuijlypMbMBkn4g6RBJu0o63sx27cSyAAAAAPRvnbr9bB9Ji939YXd/VdKVkqZ0aFkAAAAA+jFz9+ozNTta0mR3/2T2+WOS3uXup+fSTJU0Nfu4s6T7C9lsKemZyEXGpu1Wuv667BTK2M1lU8b0l51CGbu5bMqY/rJTKGM3l51CGbu5bMqY/rLXtzK+zd1H1U3t7pW/JB2t8Dua2uePSfp+yTzmVZ22W+n667JTKCPtk34ZaZ/1d9mUMf1lp1BG2mf9XTZlTH/ZKZSx9urU7WfLJG2X+zw6mwYAAAAAlepUUPMnSTua2Rgz21jScZKu79CyAAAAAPRjHRnS2d1fN7PTJf2HwpDOl7j7vSWzmdGBtN1K11+XnUIZu7lsypj+slMoYzeXTRnTX3YKZezmslMoYzeXTRnTX3YKZZTUoYECAAAAAGBd6dTtZwAAAACwThDUAAAAAEgaQQ0AAACApBHUAAAAAEhaR0Y/6zQzGy5psqRts0nLJP2Hu79QSHewpCMK6a5z9xvXTUn7ZmYm6RhJLulqSe+XNEXSIkkXufvqFvMdm+WTr/f17r6w7UKvYyXWdWV17tR66TQzu8Xd39/gu9h23EeSu/ufzGzXbJ5F7v7rOnmu19vXulBsczMbKOkUSUdK+pts8jJJ10ma6e6vrftSdp+ZDXP3VS3OO1ahj92Rz8PMJsf0NTP7hLv/ayvLLlHGqO0rSztK4dltb0h6uGy7rKP6bK1cXdz9qU4urz+qcl/R5vbVdD9eZl9fclswSfsU0v7Rm4xgZWY/dvePR1Sv0fwtH7vM7HB3T/IRJVWfG8a2Y8n+09Z5xXox+lmZjdvMPi7pbEmz9eYDPUdLOkjSP7n7j7N050naSdKPJS3Npfu4pAfd/fNNyjTD3afmPg+RdLrCie4FCs/eOUrhRPefazsUMxsg6ZPZsm5099/n8vi6u38j9/mHkraStLGkFyVtovA8n0MlPVUrY8n2OUvS8ZKuLNT7OElXuvs5ZcqYTTs4S3uzuy/JTT/Z3S/pqx3rtWVsuhLrummdC8t5n6QPKTwg9g1JD0i62N0XZ99HrZeI+vyju/9z2XQx7W1mfy5mo9Df75ckd989N19sO54t6RCFf3bcJOldkm7N0v2Hu38zl+d5amP7qlfvCtKV7mclt9embW5mV0h6QdJl6t0uJ0oa4e7HNitfg3JuJOkkhX5bOyF+QCHInpObJ6o+sfmVTdtHXR5z9+1bKOfnJH1W0kJJe0j6vLtfl323wN3Ht7DsmO3rSEm/dffnsiDk/0raU9J9kr7o7ktz88VuX7tKOl9Sj6TtJd2psJ/5bVavFc3qUqyPme0m6UcKJwD/Luksd38+++6P7r5P9j62/+wh6SJJwwt1eUHSZ9x9QZauzDFpS3d/Jvf5owonsvdI+lHtBDb2GFtm+WWOXbFpmx0/YsuosO98QdXsK/J9osy6OU9N9uNl9vWx20KW9m8l/VDSg4W0Oyj0tdlZumIAYZLeJ+kWSXL3w3N5Nl03JetzVJ1l/0DSZ7JlX5Oli9oO6zGzB9x9pzrT2zrvytKuOXbGnieV2Fecp4h2LNne0Wkb1nk9CWqiTwTM7H5J76rzH+YtFP6Tt1P2uVFHMUkPuPuOZjaiUZEk/Ze7j87N9zNJj0t6i6SdFQ6yV0k6XNI27v6xLN3FkoZI+qOkjykcGM/Mvut1EDazu919NzMbJOlJSW9191ezndKC2olpyfZ5QNI7iv/lsfAQ1Huzepcp4/+WtL+kBZIOk3Seu19QTBvbliXbPHpdN6tzbtr/kbSNpJsV/hvwiMIG+xlJ/9vdfx67XpopnkzFpCvR3tcrBFzfkPSyQvv9LptX7v5oLv/Ydrxb4cRxk6zeo939RTN7S5YuHyg13b461D6V9rOS20LTNm/ULtn8a31Xopz/KulRSb+RdHRWjt9JOkvhv1i1PhJVn9j8Si77zD7q8jV3X1PXEuW8W9K+7r7KzHoUrpz+m7t/z8zudPc9s3TFgDO/7J3cfZMsXez2dZ+775q9v0rS7ZJ+LukDkk5w94NydYndvm6XdKK732/hiuhn3f1EMztV0sHufnRu3tj6/KdCf7xdIUj8hKTD3f2hQvvErsO7JJ3m7ncU6jJR0v9z93HZ5zLHpHy7fl3SAZIul/RBSUvd/QvZd1HH2Njlx67r7HNsv2h6/Igto6Q9S+4roravsucLEedJ0fv62G0hm7ZQ0iH5E/Zs+hhJv3b3XbLPCxT+mXCxQsBrkq5QOBmXu/82Sxe1bkrW5zWF5y0+nS1XCtvP1WHRfnKWLnY7XJnVQbn8hkh6KctvsyxddN/tS+HYGXWeVGJfEdWOJdu77fMKuXvXX1lho75T6KTD66QbrhDJ1T7/WdLeddLtI+nu7P0bkh5W6Py1V+3zq4X57sr+msIJn+U+/zm/3Nz7gQoPDrpG4UTxzkKed+be31hveS20zyJJb6uT7m2S7m+hjHdLGpi931zSryWdW6f8UW1Zss1j13XTOufrU6j777P3W0i6p8x6yT6/2OC1UtLrLaSLau/s85GS5irsPKVwK0vdPhLZjnfWe9+g3k23rw61T6X9TCW2hZg2VzioHSNpo9y0jSQdq3BQL+ZXupy15WR/N5G0sGx9YvMruexXJP0vhf/UFl8vNMqzSTnvLcw3TNKNkr6r3vvIpxQC8rcVXj2S/rvs9qXcfkPS/CbbQuz29V+F7xfk3hfbPLY+xTzfp/Cf74mF/GPX4YPFeuS+W5yvcx/pisekfLsukDQ0ez9IvfcVd2V/+zzGxi4/dl2X7BdNjx+xZVT5fUXU9lVy3cScJ0Xt68tsC7W+VmvzwvSNC31tI0lfULh7YI9s2lrHuth1U7I+eysESZ/OTXukzryx2+H5Clchtm6SX5m+G3vsjDpPUoljTUw7lmzv6LSNXuvLb2qeM7NjJP3Cs98rWLgEdoyk5wtpvylpgZnNVvivjhQu5R+ksMHXnCTpQjPbVG/+t2I7SSuy76Rw8jDJ3R8rFsjMHi9Ok0IobWa/9qyls8+eS7JxLu3rkqaa2T8qXCodVsjuScvuhXX3ybllbyPp1Vy6Mu1zhqSbzexB9W6fHRQu7Zct48Asjdz9BTM7TNIMM/t5Ph/Ft2WZNo9d1zF1rlltZiPc/TmFS/MDsro9n/03QIpfL1L4j9jeXuee80J9YtPFtrfcfVbWNv/LzE4pfp8T246vmtkQd39J0l658g2XVPwd0Ulqvn2VqXdsuqr7WZltIabNj5P0LUk/NLPatrm5wm18xxXzK1HO18zs7R7+8zdeWT9097+2uP+Jza9M2gWSrnX3+XXq8snCpNhyPmVme7j7XVnaVWb2QUmXSNotl+5XkobV0hWWPSf3MXb7mmNm/yzp/2Tvj8zW/fsU+nhe7Pb1kJn9z6yOR0m6KyvfIK09aE9sfWRmwz27dc3dbzWzD0n6hcLVgJrYdfjvZnaDwolXrS7bKdz+kb+nvcwx6S1mtmdWxwHu/pds2a+Z2RvF+kUcY2OXH70vLZE25vgRW8ay+4rY7avMujlJzffjMWlqYrcFKWzDfzKzKwtpj1W4PU+SlNXh3GxdnGtmT6n+78Fj1010fTz8tvQgSX9vZrcqXK0o9kVJcduhu3/OzPaSdIWZXSvp+w3yK9N3X1DcsfMMxZ0nxe4rTlJcO8amK5u2vpjIp9Mvhf8+XSVpuUKk/4DC5b6rJI2pk34LhY3+i9nrOElbNMh7G4UTtL0ULmHnv/uspHEN5vv7wueLFQ4yxXRvl/Sfuc8/kTS5TrpPSnotsj2GStqqj/Z5sEn7bKTwH4IPZa+JCgeT0mVUOLi+p07ab0haXbYty7R5mXXdrM65dMcqXFq9SdJjkg7Npo+SdHmZ9ZJrh30apP9WC+mi2rvO9+MkfaqP75u2o6RNGsy7paTdGnzXcPvqUPtU2s/KbAsttPlISSOb5BFbzvdn/fVBhas478r1238pW5/Y/Eoue2dJoxrUZevC59hyjq7Xr7Lv9uurbRvME7s/GyRpelbvxxSC+pUKt01tX2f+mO1rc0n/kpXhm5I2zaYPlzSxbF2yeT9Sb16Fk5Uftbi+D1H4Xc0vs9dFkv6ukKZHkcdshZP0/Outue1jXi5d1DG2wfLXOibGruuS/SL6+FGyjWL2FTtL2rLZ9lVmubl5+tyPx6aJ3RZyaXeRNE3hN1QXZO93bdIOhyrcTlacXurYHlufXPq/kfQz1b9KFLUd5qZvJOlzCrd1/Xed78v03ahjZ265fZ4nqcS+omS/iG7vsusm/1ovflOTZ2YjJcndn60ov0G+9j2EvX64WMEyzCtuSDMb6+6L6kxv2j7Zf2Xk7qst3C/5TklLPPwHo2w53pLl9XKd77Z192Vrz1U9C/fkvuHuLzb4PrrOFn7H8D8ULnG/ULIcdddLVapo73bKWLbvrIvtKwX5NjezzRRO7h8qpNnd3Rv9ViJmGaZw4lNJ25bJr+pll9Hq/szMPuPuPyxMK719ZVcqB1Z1TIpV5X48y68j67DVY7aFwSI28XBluFnahsfYRssvs65Lpi19/CjbRmZ2kLvfFJO2yuUW5s3v07bJ8nnSwsAZByiMinlfkzw2k7SjQiDwfMQyx3s2GEVhetS2ELtuWq1P1czsrQq/rfp1Yfo6Oe+qt4/MpkftK9ptxz7OcycoN9hDqfOZMhFQN16SDiqRNn8f3/sULl89ozASR0/uuwUVLzcqbck8Hyt8Hqbwo60vKET4k5W7FzeX7giF+7GfUBi67w6Fe0KXSjqslTIqRM3bZO9HKdw68Y466TaT9PY603dvMd3fKNwGsSLr3LX/mk6XNKiqOufyGVt2vZTJL7Yd2ylfC2XMbzPR7dju9tWh9jmo8LnS/hjT5pI+LOm/FW4tule5+4Nj22Vd1aeieh+Uez9A0mkKt5nsV0j39RbzjOqTks4svL6Y9c0zJZ3ZSn8s0W9Pzr3fNivf85JuU/hRf0yeMwqfY+vddpv3sQ7f3W5+FbZ5veNS7DFxUJ1pda94RK7vtvZTMW2kEvvwBv2nyn3aaQr/sV8i6dNZX5ypMOrjKYV5flJrW0kHKxyvf6NwBeWYQtrxdV5LFUYZHJ9LF7UtxK7DMvUp0+YVpCvu76voZ/l6F/eRZ6r8PjK/r2i7HYv9XNJ7JM3L+szzClesfi9pjqTtovIs00DdeNWp9FENXh+StDyX7k+1DqCw43tQ2eVB1fkBcLPlVpG2Tl3Ob/C6QNKLuXQfVhgl6GJJD0n6N0k/VfhR1W6FPO/MNoYxCj8W2zmb/jblLvWXKGNUx1XkyVxsuuzzLZLem1vv5yrcAvYN5XYU7da5WPfY9VKmLWPbsUR+0WVU/DYT3Y5qc/taB+3Tif7YtM2zfGq31+yj8OPMI8u0y7qoT5l6lyjjxQq3Z50hab6k71aQZ1SfVLg17CpJ/6g3fzz9fO192eWWSVdo159Jmqpwm8eRCsOx1r4b0eA1UmEUMLVQ77bbvOp1GNuObbZ502OiKvjHS532qeqE+DGFxwTUe/1S0l/qzBPVf1T9Pu1uhRG6RkpapTdPtLfQ2oNm5P9JdlutzRVuYS7+mH51lubW3Ovl7O8tZbeFEuuwTH1i2zx6217X/Sz3vtJ9ZGw7xvSxwroelb0fI2lW9v4gSbNjyrheDBRga49DvuYrhQbLu0ph5+V10g/Ovd/Y3e+VJHe/2sLwgddYGKvbyy43Nm3JunxC4T+Kf62T/vjc+68rnDC+ZGZbSvqpux9sZrtL+n+S3p2f0d2fzMrymLvXnqHxaO0Sbskyni7pHQrDbD4qaQcPlxq3UNj51H7Q91VJe7n7ExaGK/03M/uKu8/Sm0MXlkknhcufc7LyX2NmX/PwI9Ovm1mvy5HN6rymgmbn91H3zbP3seslNj8psh1L5BddRsVvM9HtqIjtq2R9Ytsntu92oj/GtPkAd39Cktz9jxZ+WP4rM9tOddq/i/WJrneJMu7jbw5D/32FH0Bfk7VNq3nG9sl3KDxLZqjC8zBeMrMT3f2fCsuN6o8l+m3RTu7+4ez9LAuDH9QsV+jb+bbw7PNWxYwi6x3V5lWvw5LHztg2L3Ncijkm/ovCUNn3mtnRkm4ys4+5++1auz9Wup+KrM8Bkj6qcEJY/L7ec01i+0/V+7TXPNwi+JKZPVTrlx5+gF+cZyMz28zDbeKrFYI3ufszFh6JkHeMwhW2f3H3f5ckM3vE3d9XzDRmWyixDvuqT3EfHdvmUelK9PEy/Sy23rH7yNgyvh7ZjmXOVQa4+/Ls/WMKgavc/SYLz7Bpar0IalRu4/6zpO+4+z3FTMzsA7mPr5nZNrmGvtfMJilcznp7C8uNTVsmzz8pDDV4W526TC/MW7u38i/KNhJ3/3N2z2px3o08jBhycm7aAL05akaZMsbuAGJP5sqc9C238KC2WxWuLCzJ6mIqjBYUUeeamA0sdr3E5ifFt2NsfmXKGLvNlGnHmO2rTH1id5CxfXdgB/pjTJuvtGzkmCzPJ7I8ZykcVIpi6xNbzk7UO7aMZUaSi94HxfRJD6PHHWNmUxROXs9VfbH9scyBeHR2YmGSRlnv35kNyqUrNdpm5LYY2+ZVr8Myx5DYtiyTZ8wxMeofLyXLGLufiqnPAkkvefaclV4JwvNeimL7T9X7NM/16UNz3w8uziPpnyTdamY/ULht6OfZSfL71Hv0PLn7L8zsPxRGkjxZof3r/eMtdluIXYd91af4z7uqR9uM7eNl+llUvUvsI2PLuDqyHcucq8wzs5kK+5vDFW47k4UH8w5oUN7ePPIyVidfCk9gfV+D7+YWPh+gOqPPZN9NyL3/gOqMKqQw0szXWlhuVNqSeY6QNCSifb6l8ACorymMlvHV3PzF5zjsLWlwnTx6JH20hTLOV3ZPssLDGGvTByt3OVnhMvLbC/NuqnDv61+bpNtM4R7Kvxamb69wO8c9Cvfq5kfN+VBEnd9Wq3Nu2i0q3Cue++6RXLu+JbLvNs2vZDvG5lemjLHbTNO+k5vWaPvavLZ9dah9YrfDRv2xVz8r2R+bbq+Sdlf4r1px+iBJH6kzvd36xGxf7dY7toxlRlWMzTO6T+a+Gyrp2yrsy0r2x6h02ecTC68tsunbKDdKk8qNthlV79g2r3odxuZXss3L5Nn0mKhwb35xxNPRCrdlrWyxjFH7qbL1iXnF9h9Vv0/bXvWfJ3OACucf2fQdsvUzS+FWugsVrpj1tYw9Ff55+XSd72K3hdh1uL3q/85qW0kfaLHNY9PFbodl+ln0vio3fZga7yNjy3igpAPqpNlfvX+aUOZcZZDCw1K/L+lUZSOzKVyxeltUHjGJUnypwUlc5Lz7S/pBxeXpM0+FH4LVHQ41+/5QSV9S7x9qbaTCMLwx9VYYjWSt4VAl7VdnZxi1A1AY3nbHOukGKTyBu1m6A9Tg4ZER9Zmi8HTu2uc7FP5z8rDW/nFizE68r/yOrpNf0w22RDvG5lemjA1/YCfpg630x9i0Me2dpYvdQUb1XYUDYb38DlTuB8+t9sdGdVa4b/nFBq9nFB64N6mFPh67fVVe79g27/Qrtk9W1B+jD8RN8jljXdV7fXipznGuxD6tVD+T9Hfq45ioiH9sttAvovZTkW3V175ieQf2FS3t0wpp9lQ4GV6iEISs9RiGPuY9o8n3JmmzvtJGbNstbbMKv/mxVuYtuZzY41d0PyvRd1s+J84t+we5z79SnUc9KDw/7Je5z9HnKmX7Y935Or0SO9ApLlDjHx6dn0uX//HmLyLyLW6sp0fM0+eG0CzPbCOernCy85zCj7aWS/rHNtqnab1jO2Or9W6jfYr/rYxd179X7sRd4T9xIxUCiZv7WH6jE9Po/FrdYBu1T2x+Jcu4SLkfyeamnyzpoVb7o8IPDKP7bqP2LtMnq05Xsj+2tb0qXD4fp8KTx6vcvjpU79g2/3LuffGfCWs9VyKyPlFtXkj3fJa2nf7Y8nZdyCf/w9ro9ilR75bbvEF7l86vTv8pHudi92mVHpeaLLdYt6gTvqrL2Ee6tfYVFa2b0vs0STsp7OsXSfpPSX8v6dHYbaDetlAmbYltIbafTVS4remarH3ukfSkwrN8JhfyjGrzEukqP36V6Lulzokb9J/Tc9/9qY/58gNGlDlXsayvLe9rXfdZ5rIdsxMvNf6PxUqtPTrCibnXksLnE3Pp7qz3vpBX9MYauyGUzPNMhQdFjclN+x8Kl9W/0GL7xNQ7qjOWrHcn2id2Xf+pMN/3c+9vr7PRTFffO/Ey+UVtsCXaJza/MmX8O4UHsO2Ym/YVhdFL8pe2o/pjyb4be0CK3UFWna7y7bXZS9JpHdy+OlHv2DwX1Hvf4HNsfWL7WdX9saV/lNRpn8dbbJ/Y+kTlWaK9Y/Mr039a2qc16mex9SmzDhV5wld1GSP6z2kNyljVumnazxR+8P9b5W6rVQt3VeS3hZLbTey2ENvP5kn6W4WBCp7Xm6N2jlXhnKlEm8emq/T4VbLv3lnvfZ10Uf1H0oN95LG4UV3U97lK28fYUp1yfXs1WTENO1luevTGGrshlMzzTtUZL1/hP4gN69akTWLqHdUZS9a78vYpsa4X9/HdQ4XPMTvxMvlFbbAl2ic2v+gyZtMmSVqs8NCy8xTuuy4+8Ty6P8amjWnvMn2yA+m6vb1WvX11ot6xed5Z732Dz7H1ie1nVffH6ANxk/Xba3jqEu0TXe+YPMu0d2R+ZfpP7D6t0uNSmXXYV70L6So/dpboS51YN037mcJzYq6U9LikHykcSx5pofytXqmJ3RZi+9ldufcLG7VjyTaPTVfp8avZsgvpmp4bluk/kq6QdGqd6Z+UdFWj8hbSFs+n2j7GFkd6SI338d04M3vRzFZK2j17/6KZrTSzF7M0Ryk80OlWM/tRNnrTWmMUZga6+2x3/7mkJz0MCylf+0mnZfIc5HWe2OphSLtBddLHiKn3PDM7tTijmX1S4QdqebH17kT75PW1ru9oUJ/TFJ5lkPcxSce7+yNrMnZ/WGG0j4+3kN8WvQrpfnru46jc+9j2ic2vTBnl7jcrjJIyR+Ek7v2+9hOey/TH2LQx7S3F98mq03V7e616++pEvWPz9Abv632OrU9sm1fdH2O3Q9X2rXVeKxUeILwmmwbv632OrU9snrHtHZtfmf4T25ZVH5ei16H6rndeJ46dsTqxbpr2M3e/1t2PUwjGblV4htFWZnahmf1tfr4S20KZtLHbQuz6Xp17/7J666tdY7/rK13Vx69my86LOTeU4vvPGZI+YWZzzOz/Zq/fSjpF0udz6cqcq7R9jF1fhnSunLs3Hf7N3a+VdK2ZDVW4H/MMZRurwkN/ZueSR20IJfN8tY/i9fVdQzH1zso0y8xO0JsbyASF4RGPLKSN3QF0on1ifSHL8yMKw2RK0l6SNlH4L1New43GzGobTZn87jCzU939R/mJdTbY2HaMzS+6jNlOzBV2TJso/KftaTOzUHWvDYFapj/Gpo1pbym+T1aartvbqyrevtSZekflqeygqdDP3pI7UJoKz0MqUZ/YNq+6P8Zuh3L3TftYdl6Z9omtT2yese0dlV/J/hPblmeo2uNS9DpsUu/8PrLqMpbRiXUTvU/z8Iy4yyVdbuF5KcdIOkvhwaa1NLHbQpm0sWWMXd9ltsPYtLHpzlC1x7lmy17TdyPPDaP7j7s/JendFoYMf2c2+w3ufkshyzLnU20fY829lW2re3InaFJ4mulLta/Ue+fTav61jfVYd5+Um/6Gwnj4pjC8XH65g929YRQZkedaszTLswqFznhvnc4YXe8OtU+pdW1m79ebzwJpVJ8F7j6+QTl6fReZ31aSrlUYI36tDTbb8Mu0Y1R+ZcoYq0x/jE1bpr2zaU37ZCfSFeZZZ9trp7avKuvdTp59LKtsvdfKosV0Uf2x7HZYtar7Wjv75xLLaLTdlN2nVXJc6uQ6rPLYuS6sr+cgMUps213dZsvo5PGrE5odGyLziDmfars/JhfUAO3o1E68yuCiE/l1SwoHTfQfZfvjhrIdrg+61Zasw/6F9d2/EdQAAAAASFrqAwUAAAAA6OcIagAAAAAkjaAGAAAAQNIIagAAAAAk7f8DoMeBa8e9VOcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame([\n",
    "    pd.Series(y_test).value_counts().rename(\"actual\"),\n",
    "    pd.Series(y_pred).value_counts().rename(\"predicted\"),\n",
    "]).fillna(0).T.plot.bar(figsize=(14,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
